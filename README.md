# OPSO: Offline Pretraining with State-Only Imitation

OPSOëŠ” ì˜¤í”„ë¼ì¸ ì‚¬ì „í•™ìŠµ(Offline Pretraining)ê³¼ ìƒíƒœ-ì „ìš© ëª¨ë°©í•™ìŠµ(State-Only Imitation)ì„ ê²°í•©í•œ Mamba ê¸°ë°˜ ê°•í™”í•™ìŠµ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì‹œí€€ìŠ¤ ìƒíƒœ í‘œí˜„ì„ í†µí•´ íš¨ìœ¨ì ì¸ ì •ì±… í•™ìŠµê³¼ ì˜¨ë¼ì¸ ì ì‘ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.

## ğŸš€ ì£¼ìš” ê¸°ëŠ¥

### ì˜¤í”„ë¼ì¸ ì‚¬ì „í•™ìŠµ (Offline Pretraining)
- **Mamba ê¸°ë°˜ ì¸ì½”ë”**: ì‹œí€€ìŠ¤ ìƒíƒœ í‘œí˜„ í•™ìŠµ
- **Q(z,z') í•¨ìˆ˜**: ìƒíƒœ-ë‹¤ìŒìƒíƒœ ê°„ Q-ê°’ í•™ìŠµ
- **V(z,z_g) í•¨ìˆ˜**: ìƒíƒœ-ëª©í‘œ ê°„ ê°€ì¹˜ í•¨ìˆ˜ í•™ìŠµ
- **Expectile Regression**: ê°•ê±´í•œ ê°€ì¹˜ í•¨ìˆ˜ í•™ìŠµ (Ï„=0.9)
- **InfoNCE ì†ì‹¤**: ëŒ€ì¡° í•™ìŠµì„ í†µí•œ í‘œí˜„ í•™ìŠµ
- **Trajectory Alignment**: ëª©í‘œ ì§€í–¥ì  ê¶¤ì  ì •ë ¬
- **ë³´ì¡° ì†ì‹¤**: ìƒíƒœ ì˜ˆì¸¡, ë³´ìƒ/ì™„ë£Œ ì˜ˆì¸¡

### ìƒíƒœ-ì „ìš© ëª¨ë°©í•™ìŠµ (State-Only Imitation)
- **Inverse Dynamics**: ìƒíƒœ ì „ì´ë¡œë¶€í„° ì•¡ì…˜ ë³µì›
- **ê³¨-ë°”ì´ì–´ìŠ¤ íƒìƒ‰**: íš¨ìœ¨ì ì¸ íƒìƒ‰ ì „ëµ
- **Epsilon Decay**: ì ì§„ì  íƒìƒ‰ ê°ì†Œ
- **ì•¡ì…˜ ë…¸ì´ì¦ˆ ìŠ¤ì¼€ì¤„**: íƒí—˜ê³¼ í™œìš©ì˜ ê· í˜•

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
OPSO/
â”œâ”€â”€ offline_agent.py          # ì˜¤í”„ë¼ì¸ í•™ìŠµ ì—ì´ì „íŠ¸
â”œâ”€â”€ online_agent.py           # ì˜¨ë¼ì¸ í•™ìŠµ ì—ì´ì „íŠ¸
â”œâ”€â”€ offline_trainer.py        # ì˜¤í”„ë¼ì¸ í•™ìŠµ íŠ¸ë ˆì´ë„ˆ
â”œâ”€â”€ online_trainer.py         # ì˜¨ë¼ì¸ í•™ìŠµ íŠ¸ë ˆì´ë„ˆ
â”œâ”€â”€ model.py                  # Mamba ì¸ì½”ë” ëª¨ë¸
â”œâ”€â”€ ogbench_utils.py          # OGBench ë°ì´í„°ì…‹ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ utils.py                  # ê¸°íƒ€ ìœ í‹¸ë¦¬í‹°
â””â”€â”€ datasets/                 # ë°ì´í„°ì…‹ ì €ì¥ì†Œ
```

## ğŸ› ï¸ ì„¤ì¹˜ ë° ì„¤ì •

### 1. í™˜ê²½ ì„¤ì •
```bash
# Conda í™˜ê²½ ìƒì„±
conda create -n offrl python=3.10
conda activate offrl

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision torchaudio
pip install ogbench
pip install matplotlib numpy
```

### 2. ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
```bash
# OGBench ë°ì´í„°ì…‹ ìë™ ë‹¤ìš´ë¡œë“œ (ì²« ì‹¤í–‰ ì‹œ)
python offline_trainer.py --dataset antmaze-medium-navigate-v0
```

## ğŸ¯ ì‚¬ìš©ë²•

### ì˜¤í”„ë¼ì¸ í•™ìŠµ
```bash
python offline_trainer.py \
    --dataset antmaze-medium-navigate-v0 \
    --max_trajectories 100 \
    --batch_size 16 \
    --num_epochs 200
```

### ì˜¨ë¼ì¸ í•™ìŠµ
```bash
python online_trainer.py \
    --dataset antmaze-medium-navigate-v0 \
    --max_episodes 1000 \
    --batch_size 8
```

## ğŸ”§ ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°

### ì˜¤í”„ë¼ì¸ í•™ìŠµ
- `context_length`: 100 (ì‹œí€€ìŠ¤ ê¸¸ì´)
- `d_model`: 128 (ì¸ì½”ë” ì°¨ì›)
- `hidden_dim`: 256 (ì€ë‹‰ì¸µ ì°¨ì›)
- `lr`: 0.0003 (í•™ìŠµë¥ )

### ì˜¨ë¼ì¸ í•™ìŠµ
- `epsilon_start`: 0.30 (ì´ˆê¸° íƒìƒ‰ë¥ )
- `epsilon_end`: 0.05 (ìµœì¢… íƒìƒ‰ë¥ )
- `action_noise_start`: 0.20 (ì´ˆê¸° ì•¡ì…˜ ë…¸ì´ì¦ˆ)
- `action_noise_end`: 0.05 (ìµœì¢… ì•¡ì…˜ ë…¸ì´ì¦ˆ)

## ğŸ¨ ìƒíƒœ-ì „ìš© ëª¨ë°©í•™ìŠµ ì „ëµ

OPSOì˜ í•µì‹¬ì¸ ìƒíƒœ-ì „ìš© ëª¨ë°©í•™ìŠµì—ì„œ ì‚¬ìš©ë˜ëŠ” ì „ëµ:

### 1. ê³¨-ë°”ì´ì–´ìŠ¤ íƒìƒ‰
```python
# ê³¨-ë°”ì´ì–´ìŠ¤ íƒìƒ‰: z' = z + Î±(zg - z)
alpha = np.random.uniform(0.2, 1.0)
z_prime = z + alpha * (goal_z - z)

# Inverse Dynamicsë¡œ ì•¡ì…˜ ë³µì›
action = inv_dynamics(z, z_prime, goal_z)
```

### 2. Expectile Regression ê¸°ë°˜ ê°€ì¹˜ í•™ìŠµ
```python
# ë‚™ê´€ì  ê°€ì¹˜ í•¨ìˆ˜ í•™ìŠµ (Ï„=0.9)
def expectile_loss(pred, target, tau):
    diff = pred - target
    weight = torch.where(diff >= 0, tau, 1 - tau)
    return (weight * (diff ** 2)).mean()
```

### 3. Trajectory Alignment
```python
# ëª©í‘œ ì§€í–¥ì  ê¶¤ì  ì •ë ¬
d_z = zp - z  # ìƒíƒœ ì „ì´ ë°©í–¥
goal_dir = goal_z - z  # ëª©í‘œ ë°©í–¥
alignment_loss = -cosine_similarity(d_z, goal_dir)
```

## ğŸ“Š ì§€ì› ë°ì´í„°ì…‹

- `antmaze-medium-navigate-v0`
- `antmaze-medium-explore-v0`
- `antmaze-medium-stitch-v0`
- `antmaze-large-navigate-v0`
- `antmaze-large-explore-v0`
- `antmaze-large-stitch-v0`
- `humanoidmaze-medium-navigate-v0`
- `humanoidmaze-medium-stitch-v0`
- `humanoidmaze-large-navigate-v0`
- `humanoidmaze-large-stitch-v0`

## ğŸ” ëª¨ë‹ˆí„°ë§

í•™ìŠµ ê³¼ì •ì€ ë‹¤ìŒ ë©”íŠ¸ë¦­ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ë©ë‹ˆë‹¤:

### ì˜¤í”„ë¼ì¸ ì‚¬ì „í•™ìŠµ
- Critic Loss (Q-function)
- V-function Loss (Expectile Regression)
- State Loss (Next State Prediction)
- Reward Loss (Reward/Done Prediction)
- InfoNCE Loss (Contrastive Learning)
- Alignment Loss (Trajectory Alignment)

### ìƒíƒœ-ì „ìš© ëª¨ë°©í•™ìŠµ
- Train Loss (Inverse Dynamics)
- Success Rate
- Episode Reward
- Epsilon Decay
- Action Noise Schedule
- Goal-biased Exploration Rate

## ğŸ“ˆ ê²°ê³¼

í•™ìŠµ ì™„ë£Œ í›„ ë‹¤ìŒ íŒŒì¼ë“¤ì´ ìƒì„±ë©ë‹ˆë‹¤:
- `best_model.pth`: ìµœê³  ì„±ëŠ¥ ëª¨ë¸
- `training_curves.png`: í•™ìŠµ ê³¡ì„ 
- `online_training_curves.png`: ì˜¨ë¼ì¸ í•™ìŠµ ê³¡ì„ 

## ğŸ¤ ê¸°ì—¬

ì´ í”„ë¡œì íŠ¸ì— ê¸°ì—¬í•˜ê³  ì‹¶ìœ¼ì‹œë‹¤ë©´:
1. Fork the repository
2. Create your feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ”¬ í•µì‹¬ ì•„ì´ë””ì–´

OPSOëŠ” ë‹¤ìŒê³¼ ê°™ì€ í•µì‹¬ ì•„ì´ë””ì–´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•©ë‹ˆë‹¤:

1. **Offline Pretraining**: ì˜¤í”„ë¼ì¸ ë°ì´í„°ë¡œë¶€í„° ê°•ê±´í•œ ìƒíƒœ í‘œí˜„ê³¼ ê°€ì¹˜ í•¨ìˆ˜ í•™ìŠµ
2. **State-Only Imitation**: ì•¡ì…˜ ì •ë³´ ì—†ì´ ìƒíƒœ ì „ì´ë§Œìœ¼ë¡œ ì •ì±… í•™ìŠµ
3. **Expectile Regression**: ë‚™ê´€ì  ê°€ì¹˜ í•¨ìˆ˜ë¡œ íƒí—˜ ìœ ë„
4. **Trajectory Alignment**: ëª©í‘œ ì§€í–¥ì  ê¶¤ì  ì •ë ¬ë¡œ íš¨ìœ¨ì  í•™ìŠµ

## ğŸ™ ê°ì‚¬ì˜ ë§

- [OGBench](https://github.com/ogbench/ogbench) ë°ì´í„°ì…‹ ì œê³µ
- [Mamba](https://github.com/state-spaces/mamba) ì•„í‚¤í…ì²˜ ì°¸ê³ 
- Expectile Regressionê³¼ State-Only Imitation ì—°êµ¬ì— ì˜ê°ì„ ì¤€ ì„ í–‰ ì—°êµ¬ë“¤
